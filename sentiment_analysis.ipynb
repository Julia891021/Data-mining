{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-following",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "honey-litigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administration\\anaconda3\\envs\\Lab_2021\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#去除停頓詞\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import spacy  #要先下載好model\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#將文字轉換成向量\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import models\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim\n",
    "\n",
    "#Create model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "\n",
    "#評估模型好壞\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expected-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#關閉煩人的警告視窗!!!!!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-fault",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fiscal-freedom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./archive/yelp.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aerial-liberty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   business_id  10000 non-null  object\n",
      " 1   date         10000 non-null  object\n",
      " 2   review_id    10000 non-null  object\n",
      " 3   stars        10000 non-null  int64 \n",
      " 4   text         10000 non-null  object\n",
      " 5   type         10000 non-null  object\n",
      " 6   user_id      10000 non-null  object\n",
      " 7   cool         10000 non-null  int64 \n",
      " 8   useful       10000 non-null  int64 \n",
      " 9   funny        10000 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-synthetic",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-blade",
   "metadata": {},
   "source": [
    "##### a. 讀取csv檔僅保留\"text\"、\"stars\"兩個欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "understood-fountain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Quiessence is, simply put, beautiful.  Full wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Luckily, I didn't have to travel far to make m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>Definitely come for Happy hour! Prices are ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Nobuo shows his unique talents with everything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>The oldish man who owns the store is as sweet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful Vietnamese sandwich shoppe. Their ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>They have a limited time thing going on right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Good tattoo shop. Clean space, multiple artist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm 2 weeks new to Phoenix. I looked up Irish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Was it worth the 21$ for a salad and small piz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>We went here on a Saturday afternoon and this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>okay this is the best place EVER! i grew up sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>I met a friend for lunch yesterday. \\n\\nLoved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>They've gotten better and better for me in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stars                                               text\n",
       "0       5  My wife took me here on my birthday for breakf...\n",
       "1       5  I have no idea why some people give bad review...\n",
       "2       4  love the gyro plate. Rice is so good and I als...\n",
       "3       5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4       5  General Manager Scott Petello is a good egg!!!...\n",
       "5       4  Quiessence is, simply put, beautiful.  Full wi...\n",
       "6       5  Drop what you're doing and drive here. After I...\n",
       "7       4  Luckily, I didn't have to travel far to make m...\n",
       "8       4  Definitely come for Happy hour! Prices are ama...\n",
       "9       5  Nobuo shows his unique talents with everything...\n",
       "10      5  The oldish man who owns the store is as sweet ...\n",
       "11      5  Wonderful Vietnamese sandwich shoppe. Their ba...\n",
       "12      5  They have a limited time thing going on right ...\n",
       "13      4  Good tattoo shop. Clean space, multiple artist...\n",
       "14      4  I'm 2 weeks new to Phoenix. I looked up Irish ...\n",
       "15      2  Was it worth the 21$ for a salad and small piz...\n",
       "16      3  We went here on a Saturday afternoon and this ...\n",
       "17      5  okay this is the best place EVER! i grew up sh...\n",
       "18      3  I met a friend for lunch yesterday. \\n\\nLoved ...\n",
       "19      4  They've gotten better and better for me in the..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['stars','text']]\n",
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-facing",
   "metadata": {},
   "source": [
    " 將stars欄位內值大於等於4的轉成1，其餘轉成0\n",
    "\n",
    "- 1: positive\n",
    "\n",
    "- 0: negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complicated-method",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.stars[df1.stars < 4] = 0 \n",
    "df1.stars[df1.stars >= 4] = 1\n",
    "#一定要先小於4的轉成0, 再將大於等於4的轉成1 不然會全部變成0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "technical-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "#先全部轉成小寫 等等停頓詞處理有差\n",
    "for i in range(df1.shape[0]):\n",
    "    df1['text'][i] = df1['text'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sacred-exhaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>quiessence is, simply put, beautiful.  full wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>drop what you're doing and drive here. after i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>luckily, i didn't have to travel far to make m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>definitely come for happy hour! prices are ama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>nobuo shows his unique talents with everything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>the oldish man who owns the store is as sweet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>wonderful vietnamese sandwich shoppe. their ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>they have a limited time thing going on right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>good tattoo shop. clean space, multiple artist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>i'm 2 weeks new to phoenix. i looked up irish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>was it worth the 21$ for a salad and small piz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>we went here on a saturday afternoon and this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>okay this is the best place ever! i grew up sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>i met a friend for lunch yesterday. \\n\\nloved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>they've gotten better and better for me in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stars                                               text\n",
       "0       1  my wife took me here on my birthday for breakf...\n",
       "1       1  i have no idea why some people give bad review...\n",
       "2       1  love the gyro plate. rice is so good and i als...\n",
       "3       1  rosie, dakota, and i love chaparral dog park!!...\n",
       "4       1  general manager scott petello is a good egg!!!...\n",
       "5       1  quiessence is, simply put, beautiful.  full wi...\n",
       "6       1  drop what you're doing and drive here. after i...\n",
       "7       1  luckily, i didn't have to travel far to make m...\n",
       "8       1  definitely come for happy hour! prices are ama...\n",
       "9       1  nobuo shows his unique talents with everything...\n",
       "10      1  the oldish man who owns the store is as sweet ...\n",
       "11      1  wonderful vietnamese sandwich shoppe. their ba...\n",
       "12      1  they have a limited time thing going on right ...\n",
       "13      1  good tattoo shop. clean space, multiple artist...\n",
       "14      1  i'm 2 weeks new to phoenix. i looked up irish ...\n",
       "15      0  was it worth the 21$ for a salad and small piz...\n",
       "16      0  we went here on a saturday afternoon and this ...\n",
       "17      1  okay this is the best place ever! i grew up sh...\n",
       "18      0  i met a friend for lunch yesterday. \\n\\nloved ...\n",
       "19      1  they've gotten better and better for me in the..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "welcome-contrast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-afghanistan",
   "metadata": {},
   "source": [
    "將text欄位內的文字利用分割符號切割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beneficial-administrator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf1['split_text'] = df1['text'].str.split(' ')\\ndf1['split_text']\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df1['split_text'] = df1['text'].str.split(' ')\n",
    "df1['split_text']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-casino",
   "metadata": {},
   "source": [
    "##### b. 去除停頓詞 stop words \n",
    "- 停頓詞 (Stop Words) 的定義上是兩個集合：\n",
    "\n",
    "1. 這個語言中出現非常頻繁的詞。\n",
    "\n",
    "2. 文本資料中出現非常頻繁的詞。\n",
    "\n",
    "網路上有3種做法:\n",
    "\n",
    "a. spaCy\n",
    "\n",
    "b. nltk\n",
    "\n",
    "c. sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "super-brush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy has 326 stop words\n",
      "The first twenty stop words are ['a', 'anyhow', 'however', 'into', 'if', 'sixty', 'full', 'would', 'fifteen', 'very', 'please', 'everyone', 'put', 'sometime', 'itself', 'bottom', '‘ll', '‘re', 'in', 're']\n"
     ]
    }
   ],
   "source": [
    "#用 Python NLP 中的 spacy 進行stopwords 處理\n",
    "#先看一下spacy中有哪些停頓詞\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print('spaCy has {} stop words'.format(len(spacy_stopwords)))\n",
    "print('The first twenty stop words are {}'.format(list(spacy_stopwords)[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "corrected-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. imdb_df['text'].apply將每個row的text值分別取出\n",
    "2. apply(lambda x: rmsw_function(x, spacy_stopwords)) 這邊可以拆解成\n",
    "    - 將imdb_df['text'] 取出，當作lambda function的 x\n",
    "    - 然後丟進 rmsw_function 得到ruturn的值\n",
    "    - 然後放到 imdb['spacy_rmsw_text_fancy']之中\n",
    "\"\"\"\n",
    "#nltk.download('punkt')\n",
    "#def rmsw_function(text, stopword_list):\n",
    "#    return ' '.join([word for word in word_tokenize(text) if word not in stopword_list])\n",
    "#df1['rmsw_text'] = df1['text'].apply(lambda x: rmsw_function(x, spacy_stopwords))\n",
    "df1['rmsw_text'] =  df1['text'].apply(lambda x:' '.join([word for word in x.split() if word not in spacy_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reverse-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wife took birthday breakfast excellent. weather perfect sitting outside overlooking grounds absolute pleasure. waitress excellent food arrived quickly semi-busy saturday morning. looked like place fills pretty quickly earlier better. favor bloody mary. phenomenal simply best i've had. i'm pretty sure use ingredients garden blend fresh order it. amazing. menu looks excellent, white truffle scrambled eggs vegetable skillet tasty delicious. came 2 pieces griddled bread amazing absolutely meal complete. best \"toast\" i've had. anyway, can't wait back!\n"
     ]
    }
   ],
   "source": [
    "print(df1['rmsw_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "solar-carnival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my wife took me here on my birthday for breakfast and it was excellent.  the weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  our waitress was excellent and our food arrived quickly on the semi-busy saturday morning.  it looked like the place fills up pretty quickly so the earlier you get here the better.\n",
      "\n",
      "do yourself a favor and get their bloody mary.  it was phenomenal and simply the best i've ever had.  i'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  it was amazing.\n",
      "\n",
      "while everything on the menu looks excellent, i had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  it came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  it was the best \"toast\" i've ever had.\n",
      "\n",
      "anyway, i can't wait to go back!\n"
     ]
    }
   ],
   "source": [
    "print(df1['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comfortable-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   stars      10000 non-null  int64 \n",
      " 1   text       10000 non-null  object\n",
      " 2   rmsw_text  10000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "closing-whole",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-remove",
   "metadata": {},
   "source": [
    "##### c.文字探勘前處理，將文字轉換成向量，請實作 tf-idf 及 word2vec 並進行比較"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-archives",
   "metadata": {},
   "source": [
    "##### Tf-idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "clean-tsunami",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 29160)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# td-idf\n",
    "#vectorizer = CountVectorizer(stop_words = spacy_stopwords)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(df1['rmsw_text'])\n",
    "weight = tfidf.toarray()\n",
    "print(weight.shape)\n",
    "print(weight)\n",
    "df1['tfidf'] = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "portable-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   stars      10000 non-null  int64 \n",
      " 1   text       10000 non-null  object\n",
      " 2   rmsw_text  10000 non-null  object\n",
      " 3   tfidf      10000 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-cosmetic",
   "metadata": {},
   "source": [
    "##### Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "minimal-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = df1['rmsw_text'].apply(lambda x: x.split()) # tokenizing \n",
    "\n",
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            vector_size=200, # desired no. of features/independent variables\n",
    "            window=5, # context window size\n",
    "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            hs = 0,\n",
    "            negative = 10, # for negative sampling\n",
    "            workers= 32, # no.of cores\n",
    "            seed = 34\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "matched-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v.build_vocab(tokenized_tweet, progress_per = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "official-creator",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adjacent-internship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "exempt-throat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2865961, 3167730)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.train(tokenized_tweet, total_examples =model_w2v.corpus_count, epochs = model_w2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "raised-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v.save(\"./w2v_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "involved-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.6191313862800598),\n",
       " ('negative', 0.6006874442100525),\n",
       " ('ruined', 0.5913141369819641),\n",
       " ('either.', 0.5795227885246277),\n",
       " ('worse', 0.5695444345474243),\n",
       " ('previous', 0.5682346820831299),\n",
       " ('coup,', 0.5675501823425293),\n",
       " ('problems', 0.566647469997406),\n",
       " ('compelled', 0.5659807920455933),\n",
       " (\"people's\", 0.5637657046318054)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "empirical-marriage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.33778983e-01,  5.12346961e-02,  5.60183585e-01, -3.50196719e-01,\n",
       "       -3.88479918e-01,  4.57535505e-01,  4.39154170e-02, -7.24750221e-01,\n",
       "        3.84588450e-01, -2.20163912e-01,  3.51371258e-01, -8.48540187e-01,\n",
       "       -6.12686992e-01,  4.08979729e-02, -2.24307224e-01,  4.14347053e-01,\n",
       "        1.18558161e-01,  5.48949838e-01, -2.50739694e-01, -6.02923334e-01,\n",
       "       -1.47285879e-01,  8.82298723e-02, -7.05669373e-02,  2.44033530e-01,\n",
       "       -2.96892822e-01,  4.70354199e-01,  1.36866346e-01, -1.86712936e-01,\n",
       "       -9.75484475e-02,  1.97588757e-01,  3.93760026e-01, -3.95396888e-01,\n",
       "       -2.75601191e-03,  1.87644303e-01,  4.45496291e-02, -4.52596426e-01,\n",
       "       -2.70542204e-01, -4.44494814e-01,  1.47487119e-01,  8.38618204e-02,\n",
       "       -2.23444566e-01, -1.45348862e-01,  1.59412980e-01,  3.61816376e-01,\n",
       "       -4.15827990e-01,  4.83291686e-01,  4.49441910e-01,  9.52999443e-02,\n",
       "       -1.40420943e-01, -7.68519998e-01,  4.10884470e-01,  2.03868356e-02,\n",
       "       -2.37441435e-01,  2.88145185e-01,  7.38151491e-01,  6.09054327e-01,\n",
       "       -1.39890671e-01, -1.61238462e-02,  2.90187091e-01,  1.85193375e-01,\n",
       "        2.40325853e-01, -1.61028877e-01,  4.00118113e-01, -4.20335948e-01,\n",
       "       -2.51783848e-01, -7.56329969e-02, -1.21739786e-02,  2.19246686e-01,\n",
       "       -2.02409297e-01,  2.40515620e-01,  4.30021107e-01,  5.12992382e-01,\n",
       "       -1.85036719e-01, -2.28476018e-01, -1.31195977e-01,  2.02721328e-01,\n",
       "       -1.73858017e-01, -5.37617840e-02, -6.37622774e-01, -4.62858193e-02,\n",
       "        2.71791488e-01, -2.04218581e-01, -1.13388896e+00,  3.97580355e-01,\n",
       "        6.82410076e-02, -3.03658962e-01,  2.14131415e-01, -1.19964190e-01,\n",
       "        1.91939086e-01, -5.66583276e-01,  1.69200942e-01,  6.94859773e-02,\n",
       "        4.46550846e-01,  1.09183602e-01, -4.44346845e-01, -3.32025707e-01,\n",
       "       -4.06742953e-02,  3.71910244e-01,  2.13025093e-01, -7.42024362e-01,\n",
       "       -2.30607599e-01,  2.04176515e-01, -1.90514669e-01,  2.39564791e-01,\n",
       "       -2.37073705e-01,  1.86088055e-01, -6.19195625e-02, -4.97015685e-01,\n",
       "        1.11281671e-01,  2.87160903e-01, -9.05077830e-02,  4.32857215e-01,\n",
       "       -1.99089646e-02,  1.47430614e-01,  4.06246819e-02,  3.03222597e-01,\n",
       "        6.27548814e-01,  2.16121346e-01, -1.28766999e-01, -1.39159769e-01,\n",
       "       -2.96588004e-01,  6.96328208e-02, -2.00915813e-01,  1.93989709e-01,\n",
       "       -9.57564488e-02, -3.55737209e-02, -4.13866878e-01, -2.12583840e-01,\n",
       "       -4.99760777e-01,  3.42833214e-02, -2.54833400e-02, -2.67755657e-01,\n",
       "       -4.65633333e-01, -3.58870387e-01,  5.00338227e-02, -2.77573407e-01,\n",
       "        5.66849232e-01, -2.43808806e-01,  1.13944881e-01,  4.22502875e-01,\n",
       "       -1.85234636e-01,  4.55273956e-01,  4.76739943e-01,  2.78025389e-01,\n",
       "       -1.80668548e-01, -5.02139866e-01,  9.64490846e-02,  1.89870894e-01,\n",
       "        1.54747441e-01,  1.31588280e-01, -2.40856975e-01, -1.17785305e-01,\n",
       "        4.71045107e-01, -3.18201303e-01, -4.54130650e-01, -6.52440563e-02,\n",
       "        2.00196955e-04, -1.43596753e-01, -2.33723566e-01,  2.13518158e-01,\n",
       "       -1.47905022e-01,  1.96921676e-01, -7.48243704e-02, -3.35866749e-01,\n",
       "        2.41885066e-01,  3.59977692e-01,  2.07919180e-01,  4.54397410e-01,\n",
       "       -1.15129903e-01,  1.82155356e-01, -5.75146414e-02, -1.11679025e-01,\n",
       "        9.87350866e-02,  5.48541546e-01, -2.42845431e-01, -4.66729477e-02,\n",
       "       -4.97354940e-02,  1.53120421e-02, -6.99121475e-01, -5.77262104e-01,\n",
       "        8.35024714e-02,  2.85248935e-01, -2.49516740e-01, -1.10160746e-01,\n",
       "        1.39119253e-01,  3.22852544e-02, -2.43646070e-01,  3.78903329e-01,\n",
       "        2.62571722e-01, -3.35512459e-01, -3.25975264e-03, -7.72672832e-01,\n",
       "       -3.26466978e-01,  3.83640341e-02,  8.03282205e-03,  4.89701033e-02,\n",
       "        3.76462817e-01, -8.25176984e-02, -1.63466126e-01, -1.40844602e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv['bad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dense-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v.wv[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError:  # handling the case where the token is not in vocabulary\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "textile-chess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "#轉成array的形式等等丟model\n",
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 200)) \n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 200)\n",
    "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
    "# wordvec_df.shape\n",
    "print(len(wordvec_arrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "complimentary-motel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>rmsw_text</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>my wife took me here on my birthday for breakf...</td>\n",
       "      <td>wife took birthday breakfast excellent. weathe...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i have no idea why some people give bad review...</td>\n",
       "      <td>idea people bad reviews place. goes you, every...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>love the gyro plate. rice is so good and i als...</td>\n",
       "      <td>love gyro plate. rice good dig candy selection :)</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>rosie, dakota, and i love chaparral dog park!!...</td>\n",
       "      <td>rosie, dakota, love chaparral dog park!!! it's...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>general manager scott petello is a good egg!!!...</td>\n",
       "      <td>general manager scott petello good egg!!! deta...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>quiessence is, simply put, beautiful.  full wi...</td>\n",
       "      <td>quiessence is, simply put, beautiful. windows ...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>drop what you're doing and drive here. after i...</td>\n",
       "      <td>drop you're drive here. ate day more. food goo...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>luckily, i didn't have to travel far to make m...</td>\n",
       "      <td>luckily, didn't travel far connecting flight. ...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>definitely come for happy hour! prices are ama...</td>\n",
       "      <td>definitely come happy hour! prices amazing, sa...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>nobuo shows his unique talents with everything...</td>\n",
       "      <td>nobuo shows unique talents menu. carefully cra...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>the oldish man who owns the store is as sweet ...</td>\n",
       "      <td>oldish man owns store sweet be. sweeter cookie...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>wonderful vietnamese sandwich shoppe. their ba...</td>\n",
       "      <td>wonderful vietnamese sandwich shoppe. baguette...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>they have a limited time thing going on right ...</td>\n",
       "      <td>limited time thing going right bbq chicken piz...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>good tattoo shop. clean space, multiple artist...</td>\n",
       "      <td>good tattoo shop. clean space, multiple artist...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>i'm 2 weeks new to phoenix. i looked up irish ...</td>\n",
       "      <td>i'm 2 weeks new phoenix. looked irish bars tow...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>was it worth the 21$ for a salad and small piz...</td>\n",
       "      <td>worth 21$ salad small pizza? absolutely not! b...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>we went here on a saturday afternoon and this ...</td>\n",
       "      <td>went saturday afternoon place incredibly empty...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>okay this is the best place ever! i grew up sh...</td>\n",
       "      <td>okay best place ever! grew shopping los gatos,...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>i met a friend for lunch yesterday. \\n\\nloved ...</td>\n",
       "      <td>met friend lunch yesterday. loved water featur...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>they've gotten better and better for me in the...</td>\n",
       "      <td>they've gotten better better time review writt...</td>\n",
       "      <td>(0, 2307)\\t0.08236035721131113\\n  (0, 28032)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stars                                               text  \\\n",
       "0       1  my wife took me here on my birthday for breakf...   \n",
       "1       1  i have no idea why some people give bad review...   \n",
       "2       1  love the gyro plate. rice is so good and i als...   \n",
       "3       1  rosie, dakota, and i love chaparral dog park!!...   \n",
       "4       1  general manager scott petello is a good egg!!!...   \n",
       "5       1  quiessence is, simply put, beautiful.  full wi...   \n",
       "6       1  drop what you're doing and drive here. after i...   \n",
       "7       1  luckily, i didn't have to travel far to make m...   \n",
       "8       1  definitely come for happy hour! prices are ama...   \n",
       "9       1  nobuo shows his unique talents with everything...   \n",
       "10      1  the oldish man who owns the store is as sweet ...   \n",
       "11      1  wonderful vietnamese sandwich shoppe. their ba...   \n",
       "12      1  they have a limited time thing going on right ...   \n",
       "13      1  good tattoo shop. clean space, multiple artist...   \n",
       "14      1  i'm 2 weeks new to phoenix. i looked up irish ...   \n",
       "15      0  was it worth the 21$ for a salad and small piz...   \n",
       "16      0  we went here on a saturday afternoon and this ...   \n",
       "17      1  okay this is the best place ever! i grew up sh...   \n",
       "18      0  i met a friend for lunch yesterday. \\n\\nloved ...   \n",
       "19      1  they've gotten better and better for me in the...   \n",
       "\n",
       "                                            rmsw_text  \\\n",
       "0   wife took birthday breakfast excellent. weathe...   \n",
       "1   idea people bad reviews place. goes you, every...   \n",
       "2   love gyro plate. rice good dig candy selection :)   \n",
       "3   rosie, dakota, love chaparral dog park!!! it's...   \n",
       "4   general manager scott petello good egg!!! deta...   \n",
       "5   quiessence is, simply put, beautiful. windows ...   \n",
       "6   drop you're drive here. ate day more. food goo...   \n",
       "7   luckily, didn't travel far connecting flight. ...   \n",
       "8   definitely come happy hour! prices amazing, sa...   \n",
       "9   nobuo shows unique talents menu. carefully cra...   \n",
       "10  oldish man owns store sweet be. sweeter cookie...   \n",
       "11  wonderful vietnamese sandwich shoppe. baguette...   \n",
       "12  limited time thing going right bbq chicken piz...   \n",
       "13  good tattoo shop. clean space, multiple artist...   \n",
       "14  i'm 2 weeks new phoenix. looked irish bars tow...   \n",
       "15  worth 21$ salad small pizza? absolutely not! b...   \n",
       "16  went saturday afternoon place incredibly empty...   \n",
       "17  okay best place ever! grew shopping los gatos,...   \n",
       "18  met friend lunch yesterday. loved water featur...   \n",
       "19  they've gotten better better time review writt...   \n",
       "\n",
       "                                                tfidf  \n",
       "0     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "1     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "2     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "3     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "4     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "5     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "6     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "7     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "8     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "9     (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "10    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "11    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "12    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "13    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "14    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "15    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "16    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "17    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "18    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  \n",
       "19    (0, 2307)\\t0.08236035721131113\\n  (0, 28032)...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-giant",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-operations",
   "metadata": {},
   "source": [
    "##### a. 使用 Random forest進行分類 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "express-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "#先單純跑一次試試看\n",
    "y=df1['stars']\n",
    "x=tfidf\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "proud-cotton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7945"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf= RandomForestClassifier(criterion= 'entropy', max_depth= None, max_features= 'sqrt', n_estimators= 500, oob_score = True)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred= rf.predict(x_test)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "incoming-knitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7808 0.7944 0.7884 0.7944]\n",
      "78.95 %\n"
     ]
    }
   ],
   "source": [
    "#先用套件跑跑看效果\n",
    "from sklearn.model_selection import cross_val_score\n",
    "x = tfidf\n",
    "y = df1['stars']\n",
    "#rf= RandomForestClassifier(criterion= 'entropy', max_depth= None, max_features= 'sqrt', n_estimators= 100, oob_score = True)\n",
    "rf = RandomForestClassifier(criterion= 'entropy', max_features= 'sqrt', n_estimators= 500, oob_score = True)\n",
    "accuracy = cross_val_score(rf, x, y, cv=4, scoring='accuracy')\n",
    "print(accuracy)\n",
    "print(accuracy.mean()*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "welsh-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan]\n",
      "nan %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "x = tfidf\n",
    "y = wordvec_df\n",
    "#rf= RandomForestClassifier(criterion= 'entropy', max_depth= None, max_features= 'sqrt', n_estimators= 100, oob_score = True)\n",
    "rf = RandomForestClassifier(criterion= 'entropy', max_features= 'sqrt', n_estimators= 500, oob_score = True)\n",
    "accuracy = cross_val_score(rf, x, y, cv=4, scoring='accuracy')\n",
    "print(accuracy)\n",
    "print(accuracy.mean()*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-electric",
   "metadata": {},
   "source": [
    "將等等要丟入model的資料先分別取出concat起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "white-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df1['stars']\n",
    "b = pd.DataFrame(tfidf.toarray())\n",
    "df2 = pd.concat([a,b], axis = 1)\n",
    "df2 = df2.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "informational-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df1['stars']\n",
    "b = wordvec_df\n",
    "df3 = pd.concat([a,b], axis = 1)\n",
    "df3 = df3.iloc[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-replacement",
   "metadata": {},
   "source": [
    "#### k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hourly-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "model= RandomForestClassifier(criterion= 'entropy', max_features= 'sqrt', n_estimators= 100, oob_score = True)\n",
    "def cross_validation_split(dataset, folds):\n",
    "        dataset_split = []\n",
    "        df_copy = dataset\n",
    "        fold_size = int(df_copy.shape[0] / folds)\n",
    "        \n",
    "        # for loop to save each fold\n",
    "        for i in range(folds):\n",
    "            fold = []\n",
    "            # while loop to add elements to the folds\n",
    "            while len(fold) < fold_size:\n",
    "                # select a random element\n",
    "                r = random.randrange(df_copy.shape[0])\n",
    "                # determine the index of this element \n",
    "                index = df_copy.index[r]\n",
    "                # save the randomly selected line \n",
    "                fold.append(df_copy.loc[index].values.tolist())\n",
    "                # delete the randomly selected line from\n",
    "                # dataframe not to select again\n",
    "                df_copy = df_copy.drop(index)\n",
    "            # save the fold     \n",
    "            dataset_split.append(np.asarray(fold))\n",
    "            \n",
    "        return dataset_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "mobile-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_CV(dataset, f = 4):\n",
    "    data=cross_validation_split(dataset,f)\n",
    "    Accuracy=0\n",
    "    # determine training and test sets \n",
    "    for i in range(f):\n",
    "        r = list(range(f))\n",
    "        r.pop(i) #i是testing set\n",
    "        test=data[i]\n",
    "        \n",
    "        for j in r :\n",
    "            if j == r[0]:\n",
    "                cv = data[j]\n",
    "            else:    \n",
    "                cv=np.concatenate((cv,data[j]), axis=0)\n",
    "                \n",
    "        # apply RandomForest model\n",
    "        X = cv[:,1:]\n",
    "        Y = cv[:,0]\n",
    "        X_test = test[:,1:]\n",
    "        y_test = test[:,0]\n",
    "        model.fit(X,Y)\n",
    "        y_pred=model.predict(X_test)\n",
    "        Accuracy=Accuracy+metrics.accuracy_score(y_test, y_pred)\n",
    "    return Accuracy/f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "popular-strain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7772"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_fold_CV(df3) #word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "annual-pasta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857999999999999"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_fold_CV(df2) #tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
